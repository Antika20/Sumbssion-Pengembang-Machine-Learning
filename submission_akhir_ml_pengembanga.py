# -*- coding: utf-8 -*-
"""Submission Akhir ML Pengembanga.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14xE0sslO3RjQe-B0VPezQP7wZu2uBuIu

Link Dataset :
https://www.kaggle.com/datasets/nurnob101/rice-disease
"""

# install kaggle package
!pip install -q kaggle

# upload kaggle.json
from google.colab import files
files.upload()

# make directory and change permission
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

# download dataset, choose 'copy api command' from kaggle dataset
!kaggle datasets download -d nurnob101/rice-disease

from zipfile import ZipFile
file_name = "/content/rice-disease.zip"

with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print("done")

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import zipfile,os,shutil
import matplotlib.pyplot as plt

base_dir = '/content/Data-image'
train_dir = os.path.join(base_dir,'train')
validation_dir = os.path.join(base_dir, 'val')

Gudi_dir = os.path.join('/content/Data-image/Gudi_rotten')
apex_dir = os.path.join('/content/Data-image/apex_blast')
blast_dir = os.path.join('/content/Data-image/leaf_blast')
burn_dir = os.path.join('/content/Data-image/leaf_burn')
paddy_dir = os.path.join('/content/Data-image/neck_blast_paddy')

print('total training gudi images ',len(os.listdir(Gudi_dir)))

print('total training apex images ',len(os.listdir(apex_dir)))

print('total training leaf Blast images ',len(os.listdir(blast_dir)))

print('total training leaf Burn images ',len(os.listdir(burn_dir)))

print('total training nect Blast Paddy images ',len(os.listdir(paddy_dir)))

# Menghitung jumlah gambar pada dataset
number_label = {}
total_files = 0
for i in os.listdir(base_dir):
    counting = len(os.listdir(os.path.join(base_dir, i)))
    number_label[i] = counting
    total_files += counting

    print("Total Files : " + str(total_files))

# Visualisasi jumlah gambar tiap kelas

plt.bar(number_label.keys(), number_label.values());
plt.title("Jumlah Gambar Tiap Label");
plt.xlabel('Label');
plt.ylabel('Jumlah Gambar');

# Menampilkan sampel gambar tiap kelas
import matplotlib.image as mpimg

img_each_class = 1
img_samples = {}
classes = list(number_label.keys())


for c in classes:
    temp = os.listdir(os.path.join(base_dir, c))[:img_each_class]
    for item in temp:
        img_path = os.path.join(base_dir, c, item)
        img_samples[c] = img_path

for i in img_samples:
    fig = plt.gcf()
    img = mpimg.imread(img_samples[i])
    plt.title(i)
    plt.imshow(img)
    plt.show()

os.mkdir(train_dir)
os.mkdir(validation_dir) # Buat direktori Train dan val baru

train_gudi = os.path.join(train_dir, 'gudi')
train_apex = os.path.join(train_dir, 'apex')
train_blast = os.path.join(train_dir, 'blast')
train_burn = os.path.join(train_dir, 'burn')
train_paddy = os.path.join(train_dir, 'paddy')

val_gudi = os.path.join(validation_dir, 'gudi')
val_apex = os.path.join(validation_dir, 'apex')
val_blast = os.path.join(validation_dir, 'blast')
val_burn = os.path.join(validation_dir, 'burn')
val_paddy = os.path.join(validation_dir, 'paddy')

os.mkdir(train_gudi)
os.mkdir(train_apex)
os.mkdir(train_blast)
os.mkdir(train_burn)
os.mkdir(train_paddy)

os.mkdir(val_gudi)
os.mkdir(val_apex)
os.mkdir(val_blast)
os.mkdir(val_burn)
os.mkdir(val_paddy)

# memecah setiap direktori menjadi data train dan data validasi(validation 40% of dataset)
train_gudi_dir, val_gudi_dir = train_test_split(os.listdir(Gudi_dir), test_size = 0.20)
train_apex_dir, val_apex_dir = train_test_split(os.listdir(apex_dir), test_size = 0.20)
train_blast_dir, val_blast_dir = train_test_split(os.listdir(blast_dir), test_size = 0.20)
train_burn_dir, val_burn_dir = train_test_split(os.listdir(burn_dir), test_size = 0.20)
train_paddy_dir, val_paddy_dir = train_test_split(os.listdir(paddy_dir), test_size = 0.20)

for file in train_gudi_dir:
  shutil.copy(os.path.join(Gudi_dir, file), os.path.join(train_gudi, file))
for file in train_apex_dir:
  shutil.copy(os.path.join(apex_dir,file), os.path.join(train_apex,file))
for file in train_blast_dir:
  shutil.copy(os.path.join(blast_dir,file), os.path.join(train_blast,file))
for file in train_burn_dir:
  shutil.copy(os.path.join(burn_dir,file), os.path.join(train_burn,file))
for file in train_paddy_dir:
  shutil.copy(os.path.join(paddy_dir,file), os.path.join(train_paddy,file))


for file in val_gudi_dir:
  shutil.copy(os.path.join(Gudi_dir, file), os.path.join(val_gudi,file))
for file in val_apex_dir:
  shutil.copy(os.path.join(apex_dir,file), os.path.join(val_apex,file))
for file in val_blast_dir:
  shutil.copy(os.path.join(blast_dir,file), os.path.join(val_blast,file))
for file in val_burn_dir:
  shutil.copy(os.path.join(burn_dir,file), os.path.join(val_burn,file))
for file in val_paddy_dir:
  shutil.copy(os.path.join(paddy_dir,file), os.path.join(val_paddy,file))

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 30,
    horizontal_flip = True,
    shear_range = 0.2,
    fill_mode = 'nearest',
)

test_datagen = ImageDataGenerator(
    rescale = 1./225,
)

training_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(200,200),
    batch_size= 32,
    class_mode='categorical'
)

validasi_generator = test_datagen.flow_from_directory(
    validation_dir,
    target_size = (200,200),
    batch_size = 32,
    class_mode = 'categorical'
)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(200, 200, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(64,(3,3), activation='relu'), # membuat model Cnn nya 
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
  
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(5, activation='softmax')
])

model.summary() # untuk melihat arsiteksur model CNN

from PIL import Image

for image_address in os.listdir(Gudi_dir):
     try:
        Image.open(os.path.join(Gudi_dir, image_address))
     except:
          print('Error occur on ' + image_address)

# Penggunaan Callback mencegah overfitting dan menghentikan training setelah akurasi terpenuhi
class CNNCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.92 and logs.get('val_accuracy')>0.92):
      print("\nAkurasi di atas 92%, hentikan training nya Sekarang yaaa!")
      self.model.stop_training = True

callbacks = CNNCallback()

# compile model dengan 'adam' optimizer loss function 'categorical_crossentropy' 
model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

history = model.fit(
    training_generator,
    steps_per_epoch = 25, # 1312 images = batch_size * steps
    epochs = 20,
    validation_data = validasi_generator,
    validation_steps = 5, # 876 images = batch_size * steps
    verbose =1,
      callbacks=[callbacks],
    
)

test_score = model.evaluate_generator( validasi_generator)
print("[INFO] accuracy validasi: {:.2f}%".format(test_score[1] * 100))
print("[INFO] Loss validasi: ",test_score[0])

test_score = model.evaluate_generator( training_generator)
print("[INFO] accuracy training: {:.2f}%".format(test_score[1] * 100))
print("[INFO] Loss training: ",test_score[0])

plt.plot(history.history['accuracy'], label='Training', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation', color='red')
plt.title('Accuracy Training & Validation')
plt.xlabel('Epoch')
plt.legend(loc="lower right")
plt.show()

plt.plot(history.history['loss'], label='Training', color='blue')
plt.plot(history.history['val_loss'], label='Validation', color='red')
plt.title('Loss Training & Validation')
plt.xlabel('Epoch')
plt.legend(loc="upper right")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():

  
 
   # predicting images
  path = fn
  img = image.load_img(path, target_size=(200,200))
 
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
 
  classes = model.predict(images, batch_size=10) 
  if classes[0,0]!=0:
    print('ini Penyakit Gudi Rotten')
  elif classes[0,1]!=0:
    print('ini Penyakit Apex Blast')
  elif classes[0,2]!=0:
    print('ini Penyakit Leaf Blast')
  elif classes[0,3]!=0:
    print('ini Penyakit Leaf Burn ')
  else:
    print('ini Penyakit Next Blast Paddy ')

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Defining list with labels
labels = ['gudi rotten','apex blast','leaf blast','leaf burn', 'paddy']


# Check point
# Showing labels
print(labels)

# Generating Numpy array with True classes' indexes
y_true = np.random.randint(low=0, high=5, size=100, dtype=int)


# Check point
# Shwoing array
print(y_true)

# Calculating number of samples for every class
# Iterating all classes' indexes in 'y_true' array
# Using Numpy function 'unique'
# Returning sorted unique elements and their frequencies
classesIndexes, classesFrequency = np.unique(y_true, return_counts=True)


# Printing frequency (number of samples) for every class
print('classes indexes:' , classesIndexes)
print('\n')
print('classes frequency:', classesFrequency)

# Making copy of array with True classes' indexes
y_predicted = np.copy(y_true)

# Choosing randomly 25% of classes to be changed
ii = np.random.randint(low=0, high=len(y_true), size=int(0.25 * len(y_true)), dtype=int)


# Check point
# Showing chosen indexes
print(ii)

# Iterating chosen indexes and replacing them with other classes' indexes
for i in ii:
    # Generating new class index
    y_predicted[i] = np.random.randint(low=0, high=5, dtype=int)
    
    
    # Check point
    # Showing difference between True classes' indexes and Predicted ones
    print('index = {0:2d}, True class => {1}, {2} <= Predicted class'.
          format(i, y_true[i], y_predicted[i]))

# Confusion Matrix is a two dimensional matrix that visualizes the performance,
# and makes it easy to see confusion between classes,
# by providing a picture of interrelation

# Each row represents a number of actual, True class
# Each column represents a number of predicted class


# Computing Confusion Matrix to evaluate accuracy of classification
c_m = confusion_matrix(y_true, y_predicted)

# Showing Confusion Matrix in form of 2D Numpy array
print(c_m)

# Commented out IPython magic to ensure Python compatibility.

# %matplotlib inline


# Setting default size of the plot
# Setting default fontsize used in the plot
plt.rcParams['figure.figsize'] = (10.0, 9.0)
plt.rcParams['font.size'] = 20


# Implementing visualization of Confusion Matrix
display_c_m = ConfusionMatrixDisplay(c_m, display_labels=labels)


# Plotting Confusion Matrix
# Setting colour map to be used
display_c_m.plot(cmap='OrRd', xticks_rotation=25)
# Other possible options for colour map are:
# 'autumn_r', 'Blues', 'cool', 'Greens', 'Greys', 'PuRd', 'copper_r'


# Setting fontsize for xticks and yticks
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)


# Giving name to the plot
plt.title('Confusion Matrix', fontsize=24)


# Saving plot
plt.savefig('confusion_matrix.png', transparent=True, dpi=500)


# Showing the plot
plt.show()

# Showing the main classification metrics
print(classification_report(y_true, y_predicted))

import pathlib
# Menyimpan model dalam format SavedModel
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)
 
# Convert SavedModel menjadi vegs.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
 
tflite_model_file = pathlib.Path('Rice_Desease.tflite')
tflite_model_file.write_bytes(tflite_model)